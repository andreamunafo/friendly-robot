{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUCF101(base_directory = ''):\n",
    "\n",
    "    # action class labels\n",
    "    class_file = open(base_directory + '../annotations/ucfTrainTestlist/classInd.txt','r')\n",
    "    lines = class_file.readlines()\n",
    "    lines = [line.split(' ')[1].strip() for line in lines]\n",
    "    class_file.close()\n",
    "    class_list = np.asarray(lines)\n",
    "\n",
    "    # training data\n",
    "    train_file = open(base_directory + '../annotations/ucfTrainTestlist/trainlist01.txt','r')\n",
    "    lines = train_file.readlines()\n",
    "    filenames = [line.split(' ')[0] for line in lines]\n",
    "    y_train = [int(line.split(' ')[1].strip())-1 for line in lines]\n",
    "    y_train = np.asarray(y_train)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    train_file.close()\n",
    "\n",
    "    train = (np.asarray(filenames),y_train)\n",
    "\n",
    "    # testing data\n",
    "    test_file = open(base_directory + '../annotations/ucfTrainTestlist/testlist01.txt','r')\n",
    "    lines = test_file.readlines()    \n",
    "    filenames = [line.split(' ')[0].strip() for line in lines]\n",
    "    classnames = [filename.split('/')[0] for filename in filenames]\n",
    "    \n",
    "    y_test = [np.where(classname == class_list)[0][0] for classname in classnames]\n",
    "    y_test = np.asarray(y_test)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    test_file.close()\n",
    "\n",
    "    test = (np.asarray(filenames),y_test)\n",
    "\n",
    "    return class_list, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUCF101_orig(base_directory = ''):\n",
    "\n",
    "    # action class labels\n",
    "    class_file = open(base_directory + 'ucfTrainTestlist/classInd.txt','r')\n",
    "    lines = class_file.readlines()\n",
    "    lines = [line.split(' ')[1].strip() for line in lines]\n",
    "    class_file.close()\n",
    "    class_list = np.asarray(lines)\n",
    "\n",
    "    # training data\n",
    "    train_file = open(base_directory + 'ucfTrainTestlist/trainlist01.txt','r')\n",
    "    lines = train_file.readlines()\n",
    "    filenames = ['UCF-101/' + line.split(' ')[0] for line in lines]\n",
    "    y_train = [int(line.split(' ')[1].strip())-1 for line in lines]\n",
    "    y_train = np.asarray(y_train)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    train_file.close()\n",
    "\n",
    "    train = (np.asarray(filenames),y_train)\n",
    "\n",
    "    # testing data\n",
    "    test_file = open(base_directory + 'ucfTrainTestlist/testlist01.txt','r')\n",
    "    lines = test_file.readlines()\n",
    "    filenames = ['UCF-101/' + line.split(' ')[0].strip() for line in lines]\n",
    "    classnames = [filename.split('/')[1] for filename in filenames]\n",
    "    y_test = [np.where(classname == class_list)[0][0] for classname in classnames]\n",
    "    y_test = np.asarray(y_test)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    test_file.close()\n",
    "\n",
    "    test = (np.asarray(filenames),y_test)\n",
    "\n",
    "    return class_list, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSequence(args):\n",
    "    mean = np.asarray([0.433, 0.4045, 0.3776],np.float32)\n",
    "    std = np.asarray([0.1519876, 0.14855877, 0.156976],np.float32)\n",
    "\n",
    "    curr_w = 320\n",
    "    curr_h = 240\n",
    "    height = width = 224\n",
    "    num_of_frames=16\n",
    "    filetype='avi'\n",
    "\n",
    "    (filename,augment) = args    \n",
    "\n",
    "    data = np.zeros((3,num_of_frames,height,width),dtype=np.float32)\n",
    "    try:\n",
    "        if filetype == 'hdf5':\n",
    "            ### load file from HDF5\n",
    "            filename = filename.replace('.avi','.hdf5')\n",
    "            filename = filename.replace('UCF-101','UCF-101-hdf5')\n",
    "            h = h5py.File(filename,'r')\n",
    "            nFrames = len(h['video']) - 1\n",
    "            frame_index = np.random.randint(nFrames - num_of_frames)\n",
    "            video = h['video'][frame_index:(frame_index + num_of_frames)]\n",
    "        else:\n",
    "            ### load file from AVI\n",
    "            cap = cv2.VideoCapture(filename)   \n",
    "\n",
    "            if not cap.isOpened(): \n",
    "                print(f\"could not open {filename}\") \n",
    "                return\n",
    "\n",
    "            nFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            #frameWidth   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            #frameHeight  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps     = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "            frame_index = np.random.randint(nFrames - num_of_frames)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "\n",
    "            video = []        \n",
    "            f_count = 0\n",
    "            while cap.isOpened() and f_count < num_of_frames:\n",
    "                frameId = cap.get(cv2.CAP_PROP_POS_FRAMES) # current frame number\n",
    "                ret, frame = cap.read() \n",
    "                video.append(frame)\n",
    "                f_count += 1\n",
    "                \n",
    "            cap.release()\n",
    "            \n",
    "        if(augment==True):\n",
    "            ## RANDOM CROP - crop 70-100% of original size\n",
    "            ## don't maintain aspect ratio\n",
    "            resize_factor_w = 0.3*np.random.rand()+0.7\n",
    "            resize_factor_h = 0.3*np.random.rand()+0.7\n",
    "            w1 = int(curr_w*resize_factor_w)\n",
    "            h1 = int(curr_h*resize_factor_h)\n",
    "            w = np.random.randint(curr_w-w1)\n",
    "            h = np.random.randint(curr_h-h1)\n",
    "            random_crop = np.random.randint(2)\n",
    "\n",
    "            ## Random Flip\n",
    "            random_flip = np.random.randint(2)\n",
    "\n",
    "            ## Brightness +/- 15\n",
    "            brightness = 30\n",
    "            random_add = np.random.randint(brightness+1) - brightness/2.0\n",
    "\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                if(random_crop):\n",
    "                    frame = frame[h:(h+h1),w:(w+w1),:]\n",
    "                if(random_flip):\n",
    "                    frame = cv2.flip(frame,1)\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                \n",
    "                frame += random_add\n",
    "                frame[frame>255] = 255.0\n",
    "                frame[frame<0] = 0.0\n",
    "\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        else:\n",
    "            # don't augment\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        data = data.transpose(3,0,1,2)\n",
    "    except:\n",
    "        print(\"Exception: \" + filename)\n",
    "        data = np.array([])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSequence_orig(args):\n",
    "    mean = np.asarray([0.433, 0.4045, 0.3776],np.float32)\n",
    "    std = np.asarray([0.1519876, 0.14855877, 0.156976],np.float32)\n",
    "\n",
    "    curr_w = 320\n",
    "    curr_h = 240\n",
    "    height = width = 224\n",
    "    num_of_frames = 16\n",
    "\n",
    "    (filename,augment) = args\n",
    "\n",
    "    data = np.zeros((3,num_of_frames,height,width),dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        ### load file from HDF5\n",
    "        filename = filename.replace('.avi','.hdf5')\n",
    "        filename = filename.replace('UCF-101','UCF-101-hdf5')\n",
    "        h = h5py.File(filename,'r')\n",
    "        nFrames = len(h['video']) - 1\n",
    "        frame_index = np.random.randint(nFrames - num_of_frames)\n",
    "        video = h['video'][frame_index:(frame_index + num_of_frames)]\n",
    "\n",
    "        if(augment==True):\n",
    "            ## RANDOM CROP - crop 70-100% of original size\n",
    "            ## don't maintain aspect ratio\n",
    "            resize_factor_w = 0.3*np.random.rand()+0.7\n",
    "            resize_factor_h = 0.3*np.random.rand()+0.7\n",
    "            w1 = int(curr_w*resize_factor_w)\n",
    "            h1 = int(curr_h*resize_factor_h)\n",
    "            w = np.random.randint(curr_w-w1)\n",
    "            h = np.random.randint(curr_h-h1)\n",
    "            random_crop = np.random.randint(2)\n",
    "\n",
    "            ## Random Flip\n",
    "            random_flip = np.random.randint(2)\n",
    "\n",
    "            ## Brightness +/- 15\n",
    "            brightness = 30\n",
    "            random_add = np.random.randint(brightness+1) - brightness/2.0\n",
    "\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                if(random_crop):\n",
    "                    frame = frame[h:(h+h1),w:(w+w1),:]\n",
    "                if(random_flip):\n",
    "                    frame = cv2.flip(frame,1)\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                \n",
    "                frame += random_add\n",
    "                frame[frame>255] = 255.0\n",
    "                frame[frame<0] = 0.0\n",
    "\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        else:\n",
    "            # don't augment\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        data = data.transpose(3,0,1,2)\n",
    "    except:\n",
    "        print(\"Exception: \" + filename)\n",
    "        data = np.array([])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "__all__ = [\n",
    "    'ResNet', 'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "    'resnet152', 'resnet200'\n",
    "]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(\n",
    "        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n",
    "        out.size(4)).zero_()\n",
    "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "        zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 sample_size,\n",
    "                 sample_duration,\n",
    "                 shortcut_type='B',\n",
    "                 num_classes=400):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            3,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=(1, 2, 2),\n",
    "            padding=(3, 3, 3),\n",
    "            bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 256, layers[2], shortcut_type, stride=2)\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 512, layers[3], shortcut_type, stride=2)\n",
    "        last_duration = int(math.ceil(sample_duration / 16))\n",
    "        last_size = int(math.ceil(sample_size / 32))\n",
    "        self.avgpool = nn.AvgPool3d(\n",
    "            (last_duration, last_size, last_size), stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            h = self.conv1(x)\n",
    "            h = self.bn1(h)\n",
    "            h = self.relu(h)\n",
    "            h = self.maxpool(h)\n",
    "\n",
    "            h = self.layer1(h)\n",
    "            h = self.layer2(h)\n",
    "            h = self.layer3(h)\n",
    "            h = self.layer4(h)\n",
    "\n",
    "        h = self.avgpool(h)\n",
    "\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.fc(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "def get_fine_tuning_parameters(model, ft_begin_index):\n",
    "    if ft_begin_index == 0:\n",
    "        return model.parameters()\n",
    "\n",
    "    ft_module_names = []\n",
    "    for i in range(ft_begin_index, 5):\n",
    "        ft_module_names.append('layer{}'.format(i))\n",
    "    ft_module_names.append('fc')\n",
    "\n",
    "    parameters = []\n",
    "    for k, v in model.named_parameters():\n",
    "        for ft_module in ft_module_names:\n",
    "            if ft_module in k:\n",
    "                parameters.append({'params': v})\n",
    "                break\n",
    "        else:\n",
    "            parameters.append({'params': v, 'lr': 0.0})\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    print('resnet50')\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.distributed as dist\n",
    "import torchvision\n",
    "\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 101\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "num_of_epochs = 10\n",
    "\n",
    "\n",
    "data_directory = '../../data/UCF101/UCF-101/'\n",
    "class_list, train, test = getUCF101(base_directory = data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet-50-kinetics.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../actions_in_videos/model-pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:145: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "model =  resnet50(sample_size=IMAGE_SIZE, sample_duration=16)\n",
    "pretrained = torch.load('../../actions_in_videos/model-pretrained/' + 'resnet-50-kinetics.pth')\n",
    "keys = [k for k,v in pretrained['state_dict'].items()]\n",
    "pretrained_state_dict = {k[7:]: v.cpu() for k, v in pretrained['state_dict'].items()}\n",
    "model.load_state_dict(pretrained_state_dict)\n",
    "model.fc = nn.Linear(model.fc.weight.shape[1],NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# for param in model.conv1.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.bn1.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.layer1.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.layer2.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.layer3.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "for param in model.layer4[0].parameters():\n",
    "    param.requires_grad_(True)\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad_(True)\n",
    "\n",
    "params = []\n",
    "# for param in model.conv1.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.bn1.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.layer1.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.layer2.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.layer3.parameters():\n",
    "#     params.append(param)\n",
    "for param in model.layer4[0].parameters():\n",
    "    params.append(param)\n",
    "for param in model.fc.parameters():\n",
    "    params.append(param)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(params,lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "pool_threads = Pool(8,maxtasksperchild=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/UCF101/UCF-101/PommelHorse/v_PommelHorse_g16_c02.avi\r\n"
     ]
    }
   ],
   "source": [
    "ls ../../data/UCF101/UCF-101/PommelHorse/v_PommelHorse_g16_c02.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool3d(kernel_size=(1, 7, 7), stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 16, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,num_of_epochs):\n",
    "\n",
    "    ###### TRAIN\n",
    "    train_accu = []\n",
    "    model.train()\n",
    "    random_indices = np.random.permutation(len(train[0]))\n",
    "    start_time = time.time()\n",
    "    for i in range(0, len(train[0])-batch_size,batch_size):\n",
    "\n",
    "        augment = True\n",
    "        video_list = [(train[0][k],augment)\n",
    "                       for k in random_indices[i:(batch_size+i)]]\n",
    "        data = pool_threads.map(loadSequence,video_list)\n",
    "\n",
    "        next_batch = 0\n",
    "        for video in data:\n",
    "            if video.size==0: # there was an exception, skip this\n",
    "                next_batch = 1\n",
    "        if(next_batch==1):\n",
    "            continue\n",
    "\n",
    "        x = np.asarray(data,dtype=np.float32)\n",
    "        x = Variable(torch.FloatTensor(x),requires_grad=False).cuda().contiguous()\n",
    "\n",
    "        print(x.shape)\n",
    "        break\n",
    "    break\n",
    "    \n",
    "#         y = train[1][random_indices[i:(batch_size+i)]]\n",
    "#         y = torch.from_numpy(y).cuda()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             h = model.conv1(x)\n",
    "#             h = model.bn1(h)\n",
    "#             h = model.relu(h)\n",
    "#             h = model.maxpool(h)\n",
    "\n",
    "#             h = model.layer1(h)\n",
    "#             h = model.layer2(h)\n",
    "#             h = model.layer3(h)\n",
    "#         h = model.layer4[0](h)\n",
    "\n",
    "#         h = model.avgpool(h)\n",
    "\n",
    "#         h = h.view(h.size(0), -1)\n",
    "#         output = model.fc(h)\n",
    "\n",
    "#         # output = model(x)\n",
    "\n",
    "#         loss = criterion(output, y)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         prediction = output.data.max(1)[1]\n",
    "#         accuracy = ( float( prediction.eq(y.data).sum() ) /float(batch_size))*100.0\n",
    "#         if(epoch==0):\n",
    "#             print(i,accuracy)\n",
    "#         train_accu.append(accuracy)\n",
    "#     accuracy_epoch = np.mean(train_accu)\n",
    "#     print(epoch, accuracy_epoch,time.time()-start_time)\n",
    "\n",
    "#     ##### TEST\n",
    "#     model.eval()\n",
    "#     test_accu = []\n",
    "#     random_indices = np.random.permutation(len(test[0]))\n",
    "#     t1 = time.time()\n",
    "#     for i in range(0,len(test[0])-batch_size,batch_size):\n",
    "#         augment = False\n",
    "#         video_list = [(test[0][k],augment) \n",
    "#                         for k in random_indices[i:(batch_size+i)]]\n",
    "#         data = pool_threads.map(loadSequence,video_list)\n",
    "\n",
    "#         next_batch = 0\n",
    "#         for video in data:\n",
    "#             if video.size==0: # there was an exception, skip this batch\n",
    "#                 next_batch = 1\n",
    "#         if(next_batch==1):\n",
    "#             continue\n",
    "\n",
    "#         x = np.asarray(data,dtype=np.float32)\n",
    "#         x = Variable(torch.FloatTensor(x)).cuda().contiguous()\n",
    "\n",
    "#         y = test[1][random_indices[i:(batch_size+i)]]\n",
    "#         y = torch.from_numpy(y).cuda()\n",
    "\n",
    "#         # with torch.no_grad():\n",
    "#         #     output = model(x)\n",
    "#         with torch.no_grad():\n",
    "#             h = model.conv1(x)\n",
    "#             h = model.bn1(h)\n",
    "#             h = model.relu(h)\n",
    "#             h = model.maxpool(h)\n",
    "\n",
    "#             h = model.layer1(h)\n",
    "#             h = model.layer2(h)\n",
    "#             h = model.layer3(h)\n",
    "#             h = model.layer4[0](h)\n",
    "#             # h = model.layer4[1](h)\n",
    "\n",
    "#             h = model.avgpool(h)\n",
    "\n",
    "#             h = h.view(h.size(0), -1)\n",
    "#             output = model.fc(h)\n",
    "\n",
    "#         prediction = output.data.max(1)[1]\n",
    "#         accuracy = ( float( prediction.eq(y.data).sum() ) /float(batch_size))*100.0\n",
    "#         test_accu.append(accuracy)\n",
    "#         accuracy_test = np.mean(test_accu)\n",
    "\n",
    "#     print('Testing',accuracy_test,time.time()-t1)\n",
    "\n",
    "# torch.save(model,'3d_resnet.model')\n",
    "# pool_threads.close()\n",
    "# pool_threads.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "32 0.0\n",
      "64 9.375\n",
      "96 0.0\n",
      "128 0.0\n",
      "160 12.5\n",
      "192 3.125\n",
      "224 9.375\n",
      "256 9.375\n",
      "288 6.25\n",
      "320 18.75\n",
      "352 18.75\n",
      "384 9.375\n",
      "416 9.375\n",
      "448 12.5\n",
      "480 12.5\n",
      "512 15.625\n",
      "544 12.5\n",
      "576 18.75\n",
      "608 0.0\n",
      "640 25.0\n",
      "672 18.75\n",
      "704 25.0\n",
      "736 15.625\n",
      "768 15.625\n",
      "800 28.125\n",
      "832 18.75\n",
      "864 12.5\n",
      "896 18.75\n",
      "928 12.5\n",
      "960 18.75\n",
      "992 25.0\n",
      "1024 21.875\n",
      "1056 34.375\n",
      "1088 25.0\n",
      "1120 12.5\n",
      "1152 15.625\n",
      "1184 31.25\n",
      "1216 25.0\n",
      "1248 28.125\n",
      "1280 31.25\n",
      "1312 31.25\n",
      "1344 25.0\n",
      "1376 25.0\n",
      "1408 31.25\n",
      "1440 21.875\n",
      "1472 28.125\n",
      "1504 9.375\n",
      "1536 15.625\n",
      "1568 28.125\n",
      "1600 12.5\n",
      "1632 9.375\n",
      "1664 12.5\n",
      "1696 28.125\n",
      "1728 15.625\n",
      "1760 25.0\n",
      "1792 28.125\n",
      "1824 18.75\n",
      "1856 25.0\n",
      "1888 25.0\n",
      "1920 9.375\n",
      "1952 12.5\n",
      "1984 31.25\n",
      "2016 12.5\n",
      "2048 34.375\n",
      "2080 31.25\n",
      "2112 28.125\n",
      "2144 21.875\n",
      "2176 25.0\n",
      "2208 40.625\n",
      "2240 28.125\n",
      "2272 34.375\n",
      "2304 28.125\n",
      "2336 31.25\n",
      "2368 28.125\n",
      "2400 28.125\n",
      "2432 25.0\n",
      "2464 37.5\n",
      "2496 34.375\n",
      "2528 34.375\n",
      "2560 53.125\n",
      "2592 43.75\n",
      "2624 34.375\n",
      "2656 31.25\n",
      "2688 37.5\n",
      "2720 34.375\n",
      "2752 34.375\n",
      "2784 31.25\n",
      "2816 43.75\n",
      "2848 31.25\n",
      "2880 46.875\n",
      "2912 31.25\n",
      "2944 37.5\n",
      "2976 34.375\n",
      "3008 43.75\n",
      "3040 37.5\n",
      "3072 50.0\n",
      "3104 46.875\n",
      "3136 40.625\n",
      "3168 40.625\n",
      "3200 37.5\n",
      "3232 43.75\n",
      "3264 40.625\n",
      "3296 37.5\n",
      "3328 40.625\n",
      "3360 43.75\n",
      "3392 59.375\n",
      "3424 37.5\n",
      "3456 46.875\n",
      "3488 50.0\n",
      "3520 34.375\n",
      "3552 46.875\n",
      "3584 50.0\n",
      "3616 46.875\n",
      "3648 43.75\n",
      "3680 40.625\n",
      "3712 40.625\n",
      "3744 40.625\n",
      "3776 50.0\n",
      "3808 37.5\n",
      "3840 46.875\n",
      "3872 31.25\n",
      "3904 21.875\n",
      "3936 50.0\n",
      "3968 25.0\n",
      "4000 46.875\n",
      "4032 37.5\n",
      "4064 37.5\n",
      "4096 43.75\n",
      "4128 25.0\n",
      "4160 46.875\n",
      "4192 53.125\n",
      "4224 31.25\n",
      "4256 43.75\n",
      "4288 28.125\n",
      "4320 46.875\n",
      "4352 46.875\n",
      "4384 65.625\n",
      "4416 40.625\n",
      "4448 50.0\n",
      "4480 40.625\n",
      "4512 43.75\n",
      "4544 62.5\n",
      "4576 50.0\n",
      "4608 46.875\n",
      "4640 40.625\n",
      "4672 53.125\n",
      "4704 59.375\n",
      "4736 37.5\n",
      "4768 43.75\n",
      "4800 50.0\n",
      "4832 53.125\n",
      "4864 46.875\n",
      "4896 34.375\n",
      "4928 43.75\n",
      "4960 46.875\n",
      "4992 40.625\n",
      "5024 37.5\n",
      "5056 53.125\n",
      "5088 43.75\n",
      "5120 50.0\n",
      "5152 40.625\n",
      "5184 43.75\n",
      "5216 53.125\n",
      "5248 37.5\n",
      "5280 46.875\n",
      "5312 53.125\n",
      "5344 46.875\n",
      "5376 40.625\n",
      "5408 62.5\n",
      "5440 43.75\n",
      "5472 65.625\n",
      "5504 59.375\n",
      "5536 59.375\n",
      "5568 56.25\n",
      "5600 46.875\n",
      "5632 46.875\n",
      "5664 34.375\n",
      "5696 68.75\n",
      "5728 59.375\n",
      "5760 59.375\n",
      "5792 50.0\n",
      "5824 53.125\n",
      "5856 78.125\n",
      "5888 59.375\n",
      "5920 56.25\n",
      "5952 50.0\n",
      "5984 68.75\n",
      "6016 56.25\n",
      "6048 62.5\n",
      "6080 62.5\n",
      "6112 65.625\n",
      "6144 46.875\n",
      "6176 56.25\n",
      "6208 62.5\n",
      "6240 56.25\n",
      "6272 56.25\n",
      "6304 59.375\n",
      "6336 59.375\n",
      "6368 71.875\n",
      "6400 62.5\n",
      "6432 68.75\n",
      "6464 59.375\n",
      "6496 59.375\n",
      "6528 62.5\n",
      "6560 65.625\n",
      "6592 59.375\n",
      "6624 53.125\n",
      "6656 56.25\n",
      "6688 71.875\n",
      "6720 43.75\n",
      "6752 59.375\n",
      "6784 62.5\n",
      "6816 56.25\n",
      "6848 68.75\n",
      "6880 68.75\n",
      "6912 71.875\n",
      "6944 56.25\n",
      "6976 59.375\n",
      "7008 71.875\n",
      "7040 65.625\n",
      "7072 59.375\n",
      "7104 65.625\n",
      "7136 65.625\n",
      "7168 68.75\n",
      "7200 65.625\n",
      "7232 46.875\n",
      "7264 65.625\n",
      "7296 65.625\n",
      "7328 50.0\n",
      "7360 62.5\n",
      "7392 59.375\n",
      "7424 65.625\n",
      "7456 68.75\n",
      "7488 62.5\n",
      "7520 56.25\n",
      "7552 68.75\n",
      "7584 71.875\n",
      "7616 53.125\n",
      "7648 68.75\n",
      "7680 56.25\n",
      "7712 68.75\n",
      "7744 75.0\n",
      "7776 68.75\n",
      "7808 50.0\n",
      "7840 46.875\n",
      "7872 62.5\n",
      "7904 62.5\n",
      "7936 56.25\n",
      "7968 71.875\n",
      "8000 53.125\n",
      "8032 84.375\n",
      "8064 56.25\n",
      "8096 75.0\n",
      "8128 62.5\n",
      "8160 65.625\n",
      "8192 62.5\n",
      "8224 46.875\n",
      "8256 71.875\n",
      "8288 68.75\n",
      "8320 65.625\n",
      "8352 59.375\n",
      "8384 75.0\n",
      "8416 56.25\n",
      "8448 56.25\n",
      "8480 59.375\n",
      "8512 78.125\n",
      "8544 56.25\n",
      "8576 68.75\n",
      "8608 53.125\n",
      "8640 65.625\n",
      "8672 50.0\n",
      "8704 78.125\n",
      "8736 62.5\n",
      "8768 68.75\n",
      "8800 46.875\n",
      "8832 75.0\n",
      "8864 59.375\n",
      "8896 62.5\n",
      "8928 56.25\n",
      "8960 65.625\n",
      "8992 68.75\n",
      "9024 65.625\n",
      "9056 68.75\n",
      "9088 59.375\n",
      "9120 59.375\n",
      "9152 71.875\n",
      "9184 71.875\n",
      "9216 78.125\n",
      "9248 93.75\n",
      "9280 71.875\n",
      "9312 68.75\n",
      "9344 68.75\n",
      "9376 65.625\n",
      "9408 59.375\n",
      "9440 62.5\n",
      "9472 75.0\n",
      "9504 65.625\n",
      "0 45.19714765100671 522.2467203140259\n",
      "Testing 61.86440677966102 194.26180958747864\n",
      "1 78.05159395973155 525.7462601661682\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,num_of_epochs):\n",
    "\n",
    "    ###### TRAIN\n",
    "    train_accu = []\n",
    "    model.train()\n",
    "    random_indices = np.random.permutation(len(train[0]))\n",
    "    start_time = time.time()\n",
    "    for i in range(0, len(train[0])-batch_size,batch_size):\n",
    "\n",
    "        augment = True\n",
    "        video_list = [(train[0][k],augment)\n",
    "                       for k in random_indices[i:(batch_size+i)]]\n",
    "        data = pool_threads.map(loadSequence,video_list)\n",
    "\n",
    "        next_batch = 0\n",
    "        for video in data:\n",
    "            if video.size==0: # there was an exception, skip this\n",
    "                next_batch = 1\n",
    "        if(next_batch==1):\n",
    "            continue\n",
    "\n",
    "        x = np.asarray(data,dtype=np.float32)\n",
    "        x = Variable(torch.FloatTensor(x),requires_grad=False).cuda().contiguous()\n",
    "\n",
    "        y = train[1][random_indices[i:(batch_size+i)]]\n",
    "        y = torch.from_numpy(y).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            h = model.conv1(x)\n",
    "            h = model.bn1(h)\n",
    "            h = model.relu(h)\n",
    "            h = model.maxpool(h)\n",
    "\n",
    "            h = model.layer1(h)\n",
    "            h = model.layer2(h)\n",
    "            h = model.layer3(h)\n",
    "        h = model.layer4[0](h)\n",
    "\n",
    "        h = model.avgpool(h)\n",
    "\n",
    "        h = h.view(h.size(0), -1)\n",
    "        output = model.fc(h)\n",
    "\n",
    "        # output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = output.data.max(1)[1]\n",
    "        accuracy = ( float( prediction.eq(y.data).sum() ) /float(batch_size))*100.0\n",
    "        if(epoch==0):\n",
    "            print(i,accuracy)\n",
    "        train_accu.append(accuracy)\n",
    "    accuracy_epoch = np.mean(train_accu)\n",
    "    print(epoch, accuracy_epoch,time.time()-start_time)\n",
    "\n",
    "    ##### TEST\n",
    "    model.eval()\n",
    "    test_accu = []\n",
    "    random_indices = np.random.permutation(len(test[0]))\n",
    "    t1 = time.time()\n",
    "    for i in range(0,len(test[0])-batch_size,batch_size):\n",
    "        augment = False\n",
    "        video_list = [(test[0][k],augment) \n",
    "                        for k in random_indices[i:(batch_size+i)]]\n",
    "        data = pool_threads.map(loadSequence,video_list)\n",
    "\n",
    "        next_batch = 0\n",
    "        for video in data:\n",
    "            if video.size==0: # there was an exception, skip this batch\n",
    "                next_batch = 1\n",
    "        if(next_batch==1):\n",
    "            continue\n",
    "\n",
    "        x = np.asarray(data,dtype=np.float32)\n",
    "        x = Variable(torch.FloatTensor(x)).cuda().contiguous()\n",
    "\n",
    "        y = test[1][random_indices[i:(batch_size+i)]]\n",
    "        y = torch.from_numpy(y).cuda()\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     output = model(x)\n",
    "        with torch.no_grad():\n",
    "            h = model.conv1(x)\n",
    "            h = model.bn1(h)\n",
    "            h = model.relu(h)\n",
    "            h = model.maxpool(h)\n",
    "\n",
    "            h = model.layer1(h)\n",
    "            h = model.layer2(h)\n",
    "            h = model.layer3(h)\n",
    "            h = model.layer4[0](h)\n",
    "            # h = model.layer4[1](h)\n",
    "\n",
    "            h = model.avgpool(h)\n",
    "\n",
    "            h = h.view(h.size(0), -1)\n",
    "            output = model.fc(h)\n",
    "\n",
    "        prediction = output.data.max(1)[1]\n",
    "        accuracy = ( float( prediction.eq(y.data).sum() ) /float(batch_size))*100.0\n",
    "        test_accu.append(accuracy)\n",
    "        accuracy_test = np.mean(test_accu)\n",
    "\n",
    "    print('Testing',accuracy_test,time.time()-t1)\n",
    "\n",
    "torch.save(model,'3d_resnet.model')\n",
    "pool_threads.close()\n",
    "pool_threads.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
