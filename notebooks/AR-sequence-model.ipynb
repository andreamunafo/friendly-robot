{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUCF101(base_directory = ''):\n",
    "\n",
    "    # action class labels\n",
    "    class_file = open(base_directory + '../annotations/ucfTrainTestlist/classInd.txt','r')\n",
    "    lines = class_file.readlines()\n",
    "    lines = [line.split(' ')[1].strip() for line in lines]\n",
    "    class_file.close()\n",
    "    class_list = np.asarray(lines)\n",
    "\n",
    "    # training data\n",
    "    train_file = open(base_directory + '../annotations/ucfTrainTestlist/trainlist01.txt','r')\n",
    "    lines = train_file.readlines()\n",
    "    filenames = [line.split(' ')[0] for line in lines]\n",
    "    y_train = [int(line.split(' ')[1].strip())-1 for line in lines]\n",
    "    y_train = np.asarray(y_train)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    train_file.close()\n",
    "\n",
    "    train = (np.asarray(filenames),y_train)\n",
    "\n",
    "    # testing data\n",
    "    test_file = open(base_directory + '../annotations/ucfTrainTestlist/testlist01.txt','r')\n",
    "    lines = test_file.readlines()    \n",
    "    filenames = [line.split(' ')[0].strip() for line in lines]\n",
    "    classnames = [filename.split('/')[0] for filename in filenames]\n",
    "    \n",
    "    y_test = [np.where(classname == class_list)[0][0] for classname in classnames]\n",
    "    y_test = np.asarray(y_test)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    test_file.close()\n",
    "\n",
    "    test = (np.asarray(filenames),y_test)\n",
    "\n",
    "    return class_list, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUCF101_orig(base_directory = ''):\n",
    "\n",
    "    # action class labels\n",
    "    class_file = open(base_directory + 'ucfTrainTestlist/classInd.txt','r')\n",
    "    lines = class_file.readlines()\n",
    "    lines = [line.split(' ')[1].strip() for line in lines]\n",
    "    class_file.close()\n",
    "    class_list = np.asarray(lines)\n",
    "\n",
    "    # training data\n",
    "    train_file = open(base_directory + 'ucfTrainTestlist/trainlist01.txt','r')\n",
    "    lines = train_file.readlines()\n",
    "    filenames = ['UCF-101/' + line.split(' ')[0] for line in lines]\n",
    "    y_train = [int(line.split(' ')[1].strip())-1 for line in lines]\n",
    "    y_train = np.asarray(y_train)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    train_file.close()\n",
    "\n",
    "    train = (np.asarray(filenames),y_train)\n",
    "\n",
    "    # testing data\n",
    "    test_file = open(base_directory + 'ucfTrainTestlist/testlist01.txt','r')\n",
    "    lines = test_file.readlines()\n",
    "    filenames = ['UCF-101/' + line.split(' ')[0].strip() for line in lines]\n",
    "    classnames = [filename.split('/')[1] for filename in filenames]\n",
    "    y_test = [np.where(classname == class_list)[0][0] for classname in classnames]\n",
    "    y_test = np.asarray(y_test)\n",
    "    filenames = [base_directory + filename for filename in filenames]\n",
    "    test_file.close()\n",
    "\n",
    "    test = (np.asarray(filenames),y_test)\n",
    "\n",
    "    return class_list, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSequence(args):\n",
    "    mean = np.asarray([0.433, 0.4045, 0.3776],np.float32)\n",
    "    std = np.asarray([0.1519876, 0.14855877, 0.156976],np.float32)\n",
    "\n",
    "    curr_w = 320\n",
    "    curr_h = 240\n",
    "    height = width = 224\n",
    "    num_of_frames=16\n",
    "    filetype='avi'\n",
    "\n",
    "    (filename,augment) = args    \n",
    "\n",
    "    data = np.zeros((3,num_of_frames,height,width),dtype=np.float32)\n",
    "    try:\n",
    "        if filetype == 'hdf5':\n",
    "            ### load file from HDF5\n",
    "            filename = filename.replace('.avi','.hdf5')\n",
    "            filename = filename.replace('UCF-101','UCF-101-hdf5')\n",
    "            h = h5py.File(filename,'r')\n",
    "            nFrames = len(h['video']) - 1\n",
    "            frame_index = np.random.randint(nFrames - num_of_frames)\n",
    "            video = h['video'][frame_index:(frame_index + num_of_frames)]\n",
    "        else:\n",
    "            ### load file from AVI\n",
    "            cap = cv2.VideoCapture(filename)   \n",
    "\n",
    "            if not cap.isOpened(): \n",
    "                print(f\"could not open {filename}\") \n",
    "                return\n",
    "\n",
    "            nFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            #frameWidth   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            #frameHeight  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps     = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "            frame_index = np.random.randint(nFrames - num_of_frames)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "\n",
    "            video = []        \n",
    "            f_count = 0\n",
    "            while cap.isOpened() and f_count < num_of_frames:\n",
    "                frameId = cap.get(cv2.CAP_PROP_POS_FRAMES) # current frame number\n",
    "                ret, frame = cap.read() \n",
    "                video.append(frame)\n",
    "                f_count += 1\n",
    "                \n",
    "            cap.release()\n",
    "            \n",
    "        if(augment==True):\n",
    "            ## RANDOM CROP - crop 70-100% of original size\n",
    "            ## don't maintain aspect ratio\n",
    "            resize_factor_w = 0.3*np.random.rand()+0.7\n",
    "            resize_factor_h = 0.3*np.random.rand()+0.7\n",
    "            w1 = int(curr_w*resize_factor_w)\n",
    "            h1 = int(curr_h*resize_factor_h)\n",
    "            w = np.random.randint(curr_w-w1)\n",
    "            h = np.random.randint(curr_h-h1)\n",
    "            random_crop = np.random.randint(2)\n",
    "\n",
    "            ## Random Flip\n",
    "            random_flip = np.random.randint(2)\n",
    "\n",
    "            ## Brightness +/- 15\n",
    "            brightness = 30\n",
    "            random_add = np.random.randint(brightness+1) - brightness/2.0\n",
    "\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                if(random_crop):\n",
    "                    frame = frame[h:(h+h1),w:(w+w1),:]\n",
    "                if(random_flip):\n",
    "                    frame = cv2.flip(frame,1)\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                \n",
    "                frame += random_add\n",
    "                frame[frame>255] = 255.0\n",
    "                frame[frame<0] = 0.0\n",
    "\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        else:\n",
    "            # don't augment\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        data = data.transpose(3,0,1,2)\n",
    "    except:\n",
    "        print(\"Exception: \" + filename)\n",
    "        data = np.array([])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSequence_orig(args):\n",
    "    mean = np.asarray([0.433, 0.4045, 0.3776],np.float32)\n",
    "    std = np.asarray([0.1519876, 0.14855877, 0.156976],np.float32)\n",
    "\n",
    "    curr_w = 320\n",
    "    curr_h = 240\n",
    "    height = width = 224\n",
    "    num_of_frames = 16\n",
    "\n",
    "    (filename,augment) = args\n",
    "\n",
    "    data = np.zeros((3,num_of_frames,height,width),dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        ### load file from HDF5\n",
    "        filename = filename.replace('.avi','.hdf5')\n",
    "        filename = filename.replace('UCF-101','UCF-101-hdf5')\n",
    "        h = h5py.File(filename,'r')\n",
    "        nFrames = len(h['video']) - 1\n",
    "        frame_index = np.random.randint(nFrames - num_of_frames)\n",
    "        video = h['video'][frame_index:(frame_index + num_of_frames)]\n",
    "\n",
    "        if(augment==True):\n",
    "            ## RANDOM CROP - crop 70-100% of original size\n",
    "            ## don't maintain aspect ratio\n",
    "            resize_factor_w = 0.3*np.random.rand()+0.7\n",
    "            resize_factor_h = 0.3*np.random.rand()+0.7\n",
    "            w1 = int(curr_w*resize_factor_w)\n",
    "            h1 = int(curr_h*resize_factor_h)\n",
    "            w = np.random.randint(curr_w-w1)\n",
    "            h = np.random.randint(curr_h-h1)\n",
    "            random_crop = np.random.randint(2)\n",
    "\n",
    "            ## Random Flip\n",
    "            random_flip = np.random.randint(2)\n",
    "\n",
    "            ## Brightness +/- 15\n",
    "            brightness = 30\n",
    "            random_add = np.random.randint(brightness+1) - brightness/2.0\n",
    "\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                if(random_crop):\n",
    "                    frame = frame[h:(h+h1),w:(w+w1),:]\n",
    "                if(random_flip):\n",
    "                    frame = cv2.flip(frame,1)\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                \n",
    "                frame += random_add\n",
    "                frame[frame>255] = 255.0\n",
    "                frame[frame<0] = 0.0\n",
    "\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        else:\n",
    "            # don't augment\n",
    "            data = []\n",
    "            for frame in video:\n",
    "                frame = cv2.resize(frame,(width,height))\n",
    "                frame = frame.astype(np.float32)\n",
    "                frame = frame/255.0\n",
    "                frame = (frame - mean)/std\n",
    "                data.append(frame)\n",
    "            data = np.asarray(data)\n",
    "\n",
    "        data = data.transpose(3,0,1,2)\n",
    "    except:\n",
    "        print(\"Exception: \" + filename)\n",
    "        data = np.array([])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "__all__ = [\n",
    "    'ResNet', 'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "    'resnet152', 'resnet200'\n",
    "]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(\n",
    "        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n",
    "        out.size(4)).zero_()\n",
    "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "        zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 sample_size,\n",
    "                 sample_duration,\n",
    "                 shortcut_type='B',\n",
    "                 num_classes=400):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            3,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=(1, 2, 2),\n",
    "            padding=(3, 3, 3),\n",
    "            bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 256, layers[2], shortcut_type, stride=2)\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 512, layers[3], shortcut_type, stride=2)\n",
    "        last_duration = int(math.ceil(sample_duration / 16))\n",
    "        last_size = int(math.ceil(sample_size / 32))\n",
    "        self.avgpool = nn.AvgPool3d(\n",
    "            (last_duration, last_size, last_size), stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            h = self.conv1(x)\n",
    "            h = self.bn1(h)\n",
    "            h = self.relu(h)\n",
    "            h = self.maxpool(h)\n",
    "\n",
    "            h = self.layer1(h)\n",
    "            h = self.layer2(h)\n",
    "            h = self.layer3(h)\n",
    "            h = self.layer4(h)\n",
    "\n",
    "        h = self.avgpool(h)\n",
    "\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.fc(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "def get_fine_tuning_parameters(model, ft_begin_index):\n",
    "    if ft_begin_index == 0:\n",
    "        return model.parameters()\n",
    "\n",
    "    ft_module_names = []\n",
    "    for i in range(ft_begin_index, 5):\n",
    "        ft_module_names.append('layer{}'.format(i))\n",
    "    ft_module_names.append('fc')\n",
    "\n",
    "    parameters = []\n",
    "    for k, v in model.named_parameters():\n",
    "        for ft_module in ft_module_names:\n",
    "            if ft_module in k:\n",
    "                parameters.append({'params': v})\n",
    "                break\n",
    "        else:\n",
    "            parameters.append({'params': v, 'lr': 0.0})\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.distributed as dist\n",
    "import torchvision\n",
    "\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 101\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "num_of_epochs = 10\n",
    "\n",
    "\n",
    "data_directory = '../../data/UCF101/UCF-101/'\n",
    "class_list, train, test = getUCF101(base_directory = data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet-50-kinetics.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../actions_in_videos/model-pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:145: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "model =  resnet50(sample_size=IMAGE_SIZE, sample_duration=16)\n",
    "pretrained = torch.load('../../actions_in_videos/model-pretrained/' + 'resnet-50-kinetics.pth')\n",
    "keys = [k for k,v in pretrained['state_dict'].items()]\n",
    "pretrained_state_dict = {k[7:]: v.cpu() for k, v in pretrained['state_dict'].items()}\n",
    "model.load_state_dict(pretrained_state_dict)\n",
    "model.fc = nn.Linear(model.fc.weight.shape[1],NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# for param in model.conv1.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.bn1.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.layer1.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.layer2.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "# for param in model.layer3.parameters():\n",
    "#     param.requires_grad_(True)\n",
    "for param in model.layer4[0].parameters():\n",
    "    param.requires_grad_(True)\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad_(True)\n",
    "\n",
    "params = []\n",
    "# for param in model.conv1.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.bn1.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.layer1.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.layer2.parameters():\n",
    "#     params.append(param)\n",
    "# for param in model.layer3.parameters():\n",
    "#     params.append(param)\n",
    "for param in model.layer4[0].parameters():\n",
    "    params.append(param)\n",
    "for param in model.fc.parameters():\n",
    "    params.append(param)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(params,lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "pool_threads = Pool(8,maxtasksperchild=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/UCF101/UCF-101/PommelHorse/v_PommelHorse_g16_c02.avi\r\n"
     ]
    }
   ],
   "source": [
    "ls ../../data/UCF101/UCF-101/PommelHorse/v_PommelHorse_g16_c02.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "32 3.125\n",
      "64 3.125\n",
      "96 9.375\n",
      "128 3.125\n",
      "160 9.375\n",
      "192 3.125\n",
      "224 25.0\n",
      "256 3.125\n",
      "288 21.875\n",
      "320 9.375\n",
      "352 6.25\n",
      "384 18.75\n",
      "416 12.5\n",
      "448 9.375\n",
      "480 9.375\n",
      "512 21.875\n",
      "544 15.625\n",
      "576 15.625\n",
      "608 12.5\n",
      "640 18.75\n",
      "672 15.625\n",
      "704 18.75\n",
      "736 18.75\n",
      "768 18.75\n",
      "800 21.875\n",
      "832 9.375\n",
      "864 15.625\n",
      "896 25.0\n",
      "928 31.25\n",
      "960 25.0\n",
      "992 15.625\n",
      "1024 25.0\n",
      "1056 21.875\n",
      "1088 12.5\n",
      "1120 9.375\n",
      "1152 31.25\n",
      "1184 28.125\n",
      "1216 28.125\n",
      "1248 28.125\n",
      "1280 25.0\n",
      "1312 15.625\n",
      "1344 31.25\n",
      "1376 18.75\n",
      "1408 37.5\n",
      "1440 31.25\n",
      "1472 28.125\n",
      "1504 21.875\n",
      "1536 28.125\n",
      "1568 21.875\n",
      "1600 37.5\n",
      "1632 28.125\n",
      "1664 40.625\n",
      "1696 9.375\n",
      "1728 18.75\n",
      "1760 37.5\n",
      "1792 9.375\n",
      "1824 31.25\n",
      "1856 18.75\n",
      "1888 25.0\n",
      "1920 15.625\n",
      "1952 28.125\n",
      "1984 31.25\n",
      "2016 34.375\n",
      "2048 31.25\n",
      "2080 34.375\n",
      "2112 18.75\n",
      "2144 25.0\n",
      "2176 43.75\n",
      "2208 21.875\n",
      "2240 37.5\n",
      "2272 21.875\n",
      "2304 31.25\n",
      "2336 25.0\n",
      "2368 31.25\n",
      "2400 18.75\n",
      "2432 25.0\n",
      "2464 21.875\n",
      "2496 34.375\n",
      "2528 25.0\n",
      "2560 28.125\n",
      "2592 40.625\n",
      "2624 50.0\n",
      "2656 31.25\n",
      "2688 37.5\n",
      "2720 31.25\n",
      "2752 28.125\n",
      "2784 40.625\n",
      "2816 43.75\n",
      "2848 28.125\n",
      "2880 37.5\n",
      "2912 43.75\n",
      "2944 34.375\n",
      "2976 31.25\n",
      "3008 28.125\n",
      "3040 37.5\n",
      "3072 43.75\n",
      "3104 34.375\n",
      "3136 34.375\n",
      "3168 37.5\n",
      "3200 43.75\n",
      "3232 37.5\n",
      "3264 31.25\n",
      "3296 46.875\n",
      "3328 37.5\n",
      "3360 37.5\n",
      "3392 40.625\n",
      "3424 31.25\n",
      "3456 46.875\n",
      "3488 31.25\n",
      "3520 37.5\n",
      "3552 34.375\n",
      "3584 46.875\n",
      "3616 34.375\n",
      "3648 40.625\n",
      "3680 34.375\n",
      "3712 46.875\n",
      "3744 28.125\n",
      "3776 53.125\n",
      "3808 37.5\n",
      "3840 43.75\n",
      "3872 31.25\n",
      "3904 46.875\n",
      "3936 40.625\n",
      "3968 53.125\n",
      "4000 34.375\n",
      "4032 40.625\n",
      "4064 59.375\n",
      "4096 50.0\n",
      "4128 50.0\n",
      "4160 31.25\n",
      "4192 53.125\n",
      "4224 56.25\n",
      "4256 53.125\n",
      "4288 37.5\n",
      "4320 53.125\n",
      "4352 46.875\n",
      "4384 50.0\n",
      "4416 46.875\n",
      "4448 28.125\n",
      "4480 31.25\n",
      "4512 53.125\n",
      "4544 53.125\n",
      "4576 28.125\n",
      "4608 62.5\n",
      "4640 68.75\n",
      "4672 50.0\n",
      "4704 68.75\n",
      "4736 56.25\n",
      "4768 34.375\n",
      "4800 50.0\n",
      "4832 43.75\n",
      "4864 46.875\n",
      "4896 50.0\n",
      "4928 34.375\n",
      "4960 50.0\n",
      "4992 53.125\n",
      "5024 50.0\n",
      "5056 40.625\n",
      "5088 37.5\n",
      "5120 56.25\n",
      "5152 56.25\n",
      "5184 53.125\n",
      "5216 59.375\n",
      "5248 50.0\n",
      "5280 53.125\n",
      "5312 37.5\n",
      "5344 46.875\n",
      "5376 50.0\n",
      "5408 43.75\n",
      "5440 53.125\n",
      "5472 53.125\n",
      "5504 56.25\n",
      "5536 50.0\n",
      "5568 62.5\n",
      "5600 46.875\n",
      "5632 53.125\n",
      "5664 56.25\n",
      "5696 50.0\n",
      "5728 65.625\n",
      "5760 46.875\n",
      "5792 56.25\n",
      "5824 65.625\n",
      "5856 53.125\n",
      "5888 46.875\n",
      "5920 43.75\n",
      "5952 65.625\n",
      "5984 56.25\n",
      "6016 59.375\n",
      "6048 50.0\n",
      "6080 43.75\n",
      "6112 40.625\n",
      "6144 37.5\n",
      "6176 46.875\n",
      "6208 46.875\n",
      "6240 46.875\n",
      "6272 59.375\n",
      "6304 62.5\n",
      "6336 40.625\n",
      "6368 46.875\n",
      "6400 56.25\n",
      "6432 56.25\n",
      "6464 65.625\n",
      "6496 71.875\n",
      "6528 81.25\n",
      "6560 59.375\n",
      "6592 56.25\n",
      "6624 46.875\n",
      "6656 43.75\n",
      "6688 59.375\n",
      "6720 65.625\n",
      "6752 62.5\n",
      "6784 56.25\n",
      "6816 62.5\n",
      "6848 56.25\n",
      "6880 53.125\n",
      "6912 50.0\n",
      "6944 46.875\n",
      "6976 65.625\n",
      "7008 59.375\n",
      "7040 50.0\n",
      "7072 59.375\n",
      "7104 53.125\n",
      "7136 43.75\n",
      "7168 56.25\n",
      "7200 56.25\n",
      "7232 65.625\n",
      "7264 56.25\n",
      "7296 40.625\n",
      "7328 50.0\n",
      "7360 59.375\n",
      "7392 71.875\n",
      "7424 81.25\n",
      "7456 62.5\n",
      "7488 78.125\n",
      "7520 56.25\n",
      "7552 56.25\n",
      "7584 50.0\n",
      "7616 46.875\n",
      "7648 50.0\n",
      "7680 81.25\n",
      "7712 71.875\n",
      "7744 50.0\n",
      "7776 71.875\n",
      "7808 59.375\n",
      "7840 62.5\n",
      "7872 68.75\n",
      "7904 56.25\n",
      "7936 68.75\n",
      "7968 59.375\n",
      "8000 62.5\n",
      "8032 71.875\n",
      "8064 71.875\n",
      "8096 59.375\n",
      "8128 62.5\n",
      "8160 65.625\n",
      "8192 62.5\n",
      "8224 65.625\n",
      "8256 68.75\n",
      "8288 68.75\n",
      "8320 62.5\n",
      "8352 68.75\n",
      "8384 68.75\n",
      "8416 56.25\n",
      "8448 84.375\n",
      "8480 71.875\n",
      "8512 65.625\n",
      "8544 71.875\n",
      "8576 62.5\n",
      "8608 75.0\n",
      "8640 53.125\n",
      "8672 75.0\n",
      "8704 78.125\n",
      "8736 62.5\n",
      "8768 71.875\n",
      "8800 68.75\n",
      "8832 53.125\n",
      "8864 65.625\n",
      "8896 59.375\n",
      "8928 59.375\n",
      "8960 59.375\n",
      "8992 62.5\n",
      "9024 59.375\n",
      "9056 56.25\n",
      "9088 59.375\n",
      "9120 75.0\n",
      "9152 65.625\n",
      "9184 62.5\n",
      "9216 53.125\n",
      "9248 65.625\n",
      "9280 59.375\n",
      "9312 62.5\n",
      "9344 59.375\n",
      "9376 65.625\n",
      "9408 65.625\n",
      "9440 65.625\n",
      "9472 62.5\n",
      "9504 68.75\n",
      "0 44.4001677852349 365.01923418045044\n",
      "Testing 61.255296610169495 139.53896641731262\n",
      "1 78.68078859060402 368.4071354866028\n",
      "Testing 75.8739406779661 137.90398740768433\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,num_of_epochs):\n",
    "\n",
    "    ###### TRAIN\n",
    "    train_accu = []\n",
    "    model.train()\n",
    "    random_indices = np.random.permutation(len(train[0]))\n",
    "    start_time = time.time()\n",
    "    for i in range(0, len(train[0])-batch_size,batch_size):\n",
    "\n",
    "        augment = True\n",
    "        video_list = [(train[0][k],augment)\n",
    "                       for k in random_indices[i:(batch_size+i)]]\n",
    "        data = pool_threads.map(loadSequence,video_list)\n",
    "\n",
    "        next_batch = 0\n",
    "        for video in data:\n",
    "            if video.size==0: # there was an exception, skip this\n",
    "                next_batch = 1\n",
    "        if(next_batch==1):\n",
    "            continue\n",
    "\n",
    "        x = np.asarray(data,dtype=np.float32)\n",
    "        x = Variable(torch.FloatTensor(x),requires_grad=False).cuda().contiguous()\n",
    "\n",
    "        y = train[1][random_indices[i:(batch_size+i)]]\n",
    "        y = torch.from_numpy(y).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            h = model.conv1(x)\n",
    "            h = model.bn1(h)\n",
    "            h = model.relu(h)\n",
    "            h = model.maxpool(h)\n",
    "\n",
    "            h = model.layer1(h)\n",
    "            h = model.layer2(h)\n",
    "            h = model.layer3(h)\n",
    "        h = model.layer4[0](h)\n",
    "\n",
    "        h = model.avgpool(h)\n",
    "\n",
    "        h = h.view(h.size(0), -1)\n",
    "        output = model.fc(h)\n",
    "\n",
    "        # output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = output.data.max(1)[1]\n",
    "        accuracy = ( float( prediction.eq(y.data).sum() ) /float(batch_size))*100.0\n",
    "        if(epoch==0):\n",
    "            print(i,accuracy)\n",
    "        train_accu.append(accuracy)\n",
    "    accuracy_epoch = np.mean(train_accu)\n",
    "    print(epoch, accuracy_epoch,time.time()-start_time)\n",
    "\n",
    "    ##### TEST\n",
    "    model.eval()\n",
    "    test_accu = []\n",
    "    random_indices = np.random.permutation(len(test[0]))\n",
    "    t1 = time.time()\n",
    "    for i in range(0,len(test[0])-batch_size,batch_size):\n",
    "        augment = False\n",
    "        video_list = [(test[0][k],augment) \n",
    "                        for k in random_indices[i:(batch_size+i)]]\n",
    "        data = pool_threads.map(loadSequence,video_list)\n",
    "\n",
    "        next_batch = 0\n",
    "        for video in data:\n",
    "            if video.size==0: # there was an exception, skip this batch\n",
    "                next_batch = 1\n",
    "        if(next_batch==1):\n",
    "            continue\n",
    "\n",
    "        x = np.asarray(data,dtype=np.float32)\n",
    "        x = Variable(torch.FloatTensor(x)).cuda().contiguous()\n",
    "\n",
    "        y = test[1][random_indices[i:(batch_size+i)]]\n",
    "        y = torch.from_numpy(y).cuda()\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     output = model(x)\n",
    "        with torch.no_grad():\n",
    "            h = model.conv1(x)\n",
    "            h = model.bn1(h)\n",
    "            h = model.relu(h)\n",
    "            h = model.maxpool(h)\n",
    "\n",
    "            h = model.layer1(h)\n",
    "            h = model.layer2(h)\n",
    "            h = model.layer3(h)\n",
    "            h = model.layer4[0](h)\n",
    "            # h = model.layer4[1](h)\n",
    "\n",
    "            h = model.avgpool(h)\n",
    "\n",
    "            h = h.view(h.size(0), -1)\n",
    "            output = model.fc(h)\n",
    "\n",
    "        prediction = output.data.max(1)[1]\n",
    "        accuracy = ( float( prediction.eq(y.data).sum() ) /float(batch_size))*100.0\n",
    "        test_accu.append(accuracy)\n",
    "        accuracy_test = np.mean(test_accu)\n",
    "\n",
    "    print('Testing',accuracy_test,time.time()-t1)\n",
    "\n",
    "torch.save(model,'3d_resnet.model')\n",
    "pool_threads.close()\n",
    "pool_threads.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
