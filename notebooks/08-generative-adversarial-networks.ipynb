{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'andrea munafo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook plays with GANs using the MNIST dataset.\n",
    "\n",
    "Interesting references are reported at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs in brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we are interested in generating black and white square images of somthing (e.g. dogs) with a size of $nxn$ pixels.   \n",
    "We can also reshape each image to be a vector of size $N=nxn$. This means that we can represent the image of a dog as a vector of size $N$.\n",
    "This, of course, does not mean that all vectors of size $N$ represent dogs (once back to a square image) but we can say that the $N$ dimentional vectors that represent something that looks like a dog are distributed according to a very specific probability distribution over the entire $N$ dimensional vector space.\n",
    "Some points of this space represent dogs, other might represent cats, etc.\n",
    "\n",
    "The problem of generating a new image of dog is equivalent to the problem of generating a new vector according to the correct \"dog probability distribution\" [[1](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)] over the $N$ dimensional vector space. \n",
    "This is the general problem of generating a random variable with respect to a specific probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem then becomes that of using a neural network to approximate the target probability distribution.\n",
    "This is equivalent to using the inverse transform sampling method using a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first problem when trying to generate our new image of dog is that the “dog probability distribution” over the N dimensional vector space is a very complex one and we don’t know how to directly generate complex random variables. However, as we know pretty well how to generate N uncorrelated uniform random variables, we could make use of the transform method. To do so, we need to express our N dimensional random variable as the result of a very complex function applied to a simple N dimensional random variable!\n",
    "Here, we can emphasise the fact that finding the transform function is not as straightforward as just taking the closed-form inverse of the Cumulative Distribution Function (that we obviously don’t know) as we have done when describing the inverse transform method. The transform function can’t be explicitly expressed and, then, we have to learn it from data.\n",
    "\n",
    "Then, the idea is to model the transform function using a neural network that takes as input a simple N dimensional uniform random variable and that returns as output another N dimensional random variable that should follow, after training, the right “dog probability distribution”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this network we can use two methods. A direct one, where we compare the true and the generated probability distributions and then we backpropage the error. This is the idea behind Generative Matching Networks (GMNs).\n",
    "In the indirect method we do not do a direct comparison but we add an additional layer (a discrimination task between true and generated samples) that somehow tries to enforce that the true and the generated distribution are as close as possible.\n",
    "The indirect method is the one used by Generative Adversarial Networks.\n",
    "\n",
    "So, in a GAN architecture, we have a discriminator, that takes samples of true and generated data and that try to classify them as well as possible, and a generator that is trained to fool the discriminator as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a simple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "# from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "pathlib.Path(\"../results/08-generative-adversarial-networks\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(\"../saved-mdls/08-generative-adversarial-networks\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "bs = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "fake_img_size = 100\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toImg(x, mu=0.5, std=1):\n",
    "    \"\"\"Converts x to an image shape. It works for batches of inputs.\"\"\"\n",
    "    x = mu * (x + std)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some transforms to normalise the images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean = 0.1307\n",
    "ds_std = 0.3081\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((ds_mean,), (ds_std,)) # The first tuple (0.5, 0.5, 0.5) is the mean for all three channels and the second (0.5, 0.5, 0.5) is the standard deviation for all three channels.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNIST('./data', train=True, transform=img_transform, download=True)\n",
    "valid_ds = MNIST('./data', train=False, transform=img_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_ds.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the two competing networks, the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(fake_img_size, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 256), nn.ReLU(True), nn.Linear(256, 784), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.generator(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2), nn.Linear(256, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.discriminator(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dnet = Discriminator()\n",
    "Gnet = Generator()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    Dnet = Dnet.cuda()\n",
    "    Gnet = Gnet.cuda()\n",
    "    \n",
    "loss_fn = nn.BCELoss() # Binary cross entropy loss\n",
    "\n",
    "\n",
    "# We need to optimizers, one per network.\n",
    "d_optimizer = torch.optim.Adam(Dnet.parameters(), lr=learning_rate)\n",
    "g_optimizer = torch.optim.Adam(Gnet.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10]. Saving a sample of real images.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for x, y in train_dl: # x is the real image, y is the real label\n",
    "        img_nums = x.shape[0]\n",
    "        \n",
    "        # In this case, we want to discriminate which one is real and which is fake.\n",
    "        # So we create the labels accordingly.\n",
    "        real_label = Variable(torch.ones(img_nums)).to(device)\n",
    "        fake_label = Variable(torch.zeros(img_nums)).to(device)\n",
    "\n",
    "        # Train the discriminator network\n",
    "        x = x.view(x.size(0), -1).to(device)\n",
    "        \n",
    "        # compute loss of real_img\n",
    "        d_real_out = Dnet(x)\n",
    "        d_loss_real = loss_fn(d_real_out, real_label) \n",
    "        \n",
    "        # generate the image of a specific dimention (z_dimention).\n",
    "        # We start from noise.\n",
    "        z = Variable(torch.randn(img_nums, fake_img_size)).to(device)\n",
    "        fake_img = Gnet(z)\n",
    "        d_fake_out = Dnet(fake_img)\n",
    "        d_loss_fake = loss_fn(d_fake_out, fake_label)\n",
    "        \n",
    "        real_scores = d_real_out  # closer to 1 means better\n",
    "        fake_scores = d_fake_out  # closer to 0 means better\n",
    "\n",
    "        # backprop\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()        \n",
    "        \n",
    "        # Train the generator network\n",
    "        \n",
    "        # compute loss of fake_img\n",
    "        z = Variable(torch.randn(img_nums, fake_img_size)).to(device)\n",
    "        fake_img = Gnet(z)\n",
    "        output = Dnet(fake_img)\n",
    "        g_loss = loss_fn(output, real_label) # not sure why I have real_label here!\n",
    "\n",
    "        # backprop and optimize\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        \n",
    "    if epoch == 0:\n",
    "        print('Epoch [{}/{}], saving a sample of real images.'.format(epoch, num_epochs))\n",
    "        real_images = toImg(x.cpu().data)\n",
    "        save_image(real_images, '../results/08-generative-adversarial-networks/real-images.png')\n",
    "        \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], d_loss: {:.6f}, g_loss: {:.6f} '\n",
    "              'D real: {:.6f}, D fake: {:.6f}'.format(\n",
    "              epoch, num_epochs, d_loss.data[0], g_loss.data[0],\n",
    "              real_scores.data.mean(), fake_scores.data.mean()))\n",
    "\n",
    "\n",
    "\n",
    "    fake_images = toImg(fake_img.cpu().data)\n",
    "    save_image(fake_images, '../results/08-generative-adversarial-networks/fake-images-{}.png'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As suggested in https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(Gnet, '../saved-mdls/08-generative-adversarial-networks/generator-{}e.pt'.format(epoch+1))\n",
    "torch.save(Dnet, '../saved-mdls/08-generative-adversarial-networks/distriminator-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. [Understanding GANS](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)\n",
    "2. [Data science courses](https://www.youtube.com/channel/UCKJNzy_GuvX3SAg3ipaGa8A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/andreamunafo/opt/anaconda3/envs/number-five-dl/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m(2058)\u001b[0;36mbinary_cross_entropy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2056 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2057 \u001b[0;31m        raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n",
      "\u001b[0m\u001b[0;32m-> 2058 \u001b[0;31m                         \"!= input nelement ({})\".format(target.numel(), input.numel()))\n",
      "\u001b[0m\u001b[0;32m   2059 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2060 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
